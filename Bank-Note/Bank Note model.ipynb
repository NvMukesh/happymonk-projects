{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <tr>\n",
    "        <td width=\"15%\">\n",
    "        </td>\n",
    "        <td>\n",
    "            <div align=\"Middle\">\n",
    "                <font size=25px>\n",
    "                    <b>  Banknote Authentication dataset Classifier using ANN with one hidden layer\n",
    "                    </b>\n",
    "                </font>\n",
    "            </div>\n",
    "        </td>\n",
    "    </tr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Downloaded directly from the curated repository "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Definition:\n",
    " 5 columns and 1372 records "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "**[1. Import Python modules](#1)**<br>\n",
    "**[2. DEF functions - Activation functions, Neuron Layer, Weigths and bias](#2)**<br>\n",
    "**[3. Model training](#3)**<br>\n",
    "**[4. Epoch def function](#4)**<br>\n",
    "**[5. Model summary](#5)**<br>\n",
    "**[6. Print initial and final weights](#6)**<br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## Importing Libraries and Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the Banknote Authentication dataset\n",
    "data = pd.read_csv(r\"E:\\DS workspace\\ML DL Python\\Happymonk\\MLP model from github\\Bank note\\BankNote_Authentication.csv\")\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# One-hot encode the target labels\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_encoded = encoder.transform(y_test.reshape(-1, 1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## DEF functions - Activation functions, Neuron Layer, Weigths and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the initial parameters\n",
    "np.random.seed(42)\n",
    "m = X_train.shape[1]\n",
    "n = 8\n",
    "p = 4\n",
    "k = len(np.unique(y_train))\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Initialize the weights and biases\n",
    "W1 = np.random.randn(m, n)\n",
    "b1 = np.zeros((1, n))\n",
    "W2 = np.random.randn(n, p)\n",
    "b2 = np.zeros((1, p))\n",
    "W3 = np.random.randn(p, k)\n",
    "b3 = np.zeros((1, k))\n",
    "K = np.random.randn(3)\n",
    "\n",
    "# Define the activation function\n",
    "def activation_function(x, k0, k1):\n",
    "    return k0 + k1 * x\n",
    "\n",
    "# Forward propagation\n",
    "def forward_propagation(X, W1, b1, W2, b2, K):\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = activation_function(z1, K[0], K[1])\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = activation_function(z2, K[0], K[1])\n",
    "    z3 = np.dot(a2, W3) + b3\n",
    "    a3 = softmax(z3)\n",
    "    return z1, a1, z2, a2, z3, a3\n",
    "\n",
    "# Softmax activation function\n",
    "def softmax(x):\n",
    "    exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exps / np.sum(exps, axis=1, keepdims=True)\n",
    "\n",
    "# Backward propagation\n",
    "def backward_propagation(X, y, z1, a1, z2, a2, z3, a3, W2, K):\n",
    "    m = X.shape[0]\n",
    "    dz3 = a3 - y\n",
    "    dw3 = (1 / m) * np.dot(a2.T, dz3)\n",
    "    db3 = (1 / m) * np.sum(dz3, axis=0)\n",
    "    da2 = np.dot(dz3, W3.T)\n",
    "    dz2 = activation_derivative(a2, K[1]) * da2\n",
    "    dw2 = (1 / m) * np.dot(a1.T, dz2)\n",
    "    db2 = (1 / m) * np.sum(dz2, axis=0)\n",
    "    da1 = np.dot(dz2, W2.T)\n",
    "    dz1 = activation_derivative(a1, K[1]) * da1\n",
    "    dw1 = (1 / m) * np.dot(X.T, dz1)\n",
    "    db1 = (1 / m) * np.sum(dz1, axis=0)\n",
    "    dK2 = np.array([np.mean(da2), np.mean(da2 * z2), np.mean(da2 * z2**2)])\n",
    "    dK1 = np.array([np.mean(da1), np.mean(da1 * z1), np.mean(da1 * z1**2)])\n",
    "    dK = dK2 + dK1\n",
    "    return dw1, db1, dw2, db2, dw3, db3, dK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Activation derivative\n",
    "def activation_derivative(x, k1):\n",
    "    return k1\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "f1_scores = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward propagation\n",
    "    z1, a1, z2, a2, z3, a3 = forward_propagation(X_train, W1, b1, W2, b2, K)\n",
    "\n",
    "    # Backward propagation\n",
    "    dw1, db1, dw2, db2, dw3, db3, dK = backward_propagation(X_train, y_train_encoded, z1, a1, z2, a2, z3, a3, W2, K)\n",
    "\n",
    "    # Update parameters\n",
    "    W1 -= learning_rate * dw1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dw2\n",
    "    b2 -= learning_rate * db2\n",
    "    W3 -= learning_rate * dw3\n",
    "    b3 -= learning_rate * db3\n",
    "    K -= learning_rate * dK\n",
    "\n",
    "    # Calculate train and test loss\n",
    "    _, _, _, _, _, train_predictions = forward_propagation(X_train, W1, b1, W2, b2, K)\n",
    "    _, _, _, _, _, test_predictions = forward_propagation(X_test, W1, b1, W2, b2, K)\n",
    "    train_loss = -np.mean(np.sum(y_train_encoded * np.log(train_predictions), axis=1))\n",
    "    test_loss = -np.mean(np.sum(y_test_encoded * np.log(test_predictions), axis=1))\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    # Calculate train and test accuracy\n",
    "    train_accuracy = accuracy_score(y_train, np.argmax(train_predictions, axis=1))\n",
    "    test_accuracy = accuracy_score(y_test, np.argmax(test_predictions, axis=1))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Calculate F1-Score\n",
    "    f1 = f1_score(y_test, np.argmax(test_predictions, axis=1), average='weighted')\n",
    "    f1_scores.append(f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4'></a>\n",
    "## Epoch def function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(epochs):\n",
    "    # Forward propagation\n",
    "    z1, a1, z2, a2, z3, a3 = forward_propagation(X_train, W1, b1, W2, b2, K)\n",
    "\n",
    "    # Backward propagation\n",
    "    dw1, db1, dw2, db2, dw3, db3, dK = backward_propagation(X_train, y_train_encoded, z1, a1, z2, a2, z3, a3, W2, K)\n",
    "\n",
    "    # Update parameters\n",
    "    W1 -= learning_rate * dw1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dw2\n",
    "    b2 -= learning_rate * db2\n",
    "    W3 -= learning_rate * dw3\n",
    "    b3 -= learning_rate * db3\n",
    "    K -= learning_rate * dK\n",
    "\n",
    "    # Calculate train and test loss\n",
    "    _, _, _, _, _, train_predictions = forward_propagation(X_train, W1, b1, W2, b2, K)\n",
    "    _, _, _, _, _, test_predictions = forward_propagation(X_test, W1, b1, W2, b2, K)\n",
    "    train_loss = -np.mean(np.sum(y_train_encoded * np.log(train_predictions), axis=1))\n",
    "    test_loss = -np.mean(np.sum(y_test_encoded * np.log(test_predictions), axis=1))\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    # Calculate train and test accuracy\n",
    "    train_accuracy = accuracy_score(y_train, np.argmax(train_predictions, axis=1))\n",
    "    test_accuracy = accuracy_score(y_test, np.argmax(test_predictions, axis=1))\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    # Calculate F1-Score\n",
    "    f1 = f1_score(y_test, np.argmax(test_predictions, axis=1), average='weighted')\n",
    "    f1_scores.append(f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='5'></a>\n",
    "## Model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Summary:\n",
      "Number of features: 4\n",
      "Number of hidden nodes: 8\n",
      "Number of output nodes: 2\n",
      "Number of training examples: 1096\n",
      "Number of test examples: 275\n",
      "Number of epochs: 1000\n"
     ]
    }
   ],
   "source": [
    "# Model summary\n",
    "print(\"\\nModel Summary:\")\n",
    "print(\"Number of features:\", m)\n",
    "print(\"Number of hidden nodes:\", n)\n",
    "print(\"Number of output nodes:\", k)\n",
    "print(\"Number of training examples:\", X_train.shape[0])\n",
    "print(\"Number of test examples:\", X_test.shape[0])\n",
    "print(\"Number of epochs:\", epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='7'></a>\n",
    "## Print initial and final weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights:\n",
      "W1:\n",
      " [[ 0.63540203 -0.09535129  0.63272378  1.51729196 -0.12047677 -0.27462461\n",
      "   1.56774133  0.81283306]\n",
      " [-0.42394748  0.51913835 -0.48490168 -0.45185685  0.2746626  -1.86511179\n",
      "  -1.68715956 -0.57459632]\n",
      " [-0.84516675  0.38189643 -0.92112156 -1.41932565  1.60345755 -0.29908145\n",
      "   0.04022099 -1.35529317]\n",
      " [-0.44129968  0.14218005 -1.15952348  0.36902457 -0.5185287  -0.32538224\n",
      "  -0.61433177  1.88676441]]\n",
      "b1:\n",
      " [[-0.29687453 -0.10538176  0.05024016 -0.0035781  -0.2640211   0.07953984\n",
      "   0.0029589  -0.09849247]]\n",
      "W2:\n",
      " [[ 0.00706252 -1.01017751  0.79005364 -1.16758938]\n",
      " [ 0.18902981 -1.9930427  -1.29822106  0.16634437]\n",
      " [ 0.7673436   0.23995278 -0.16145651 -0.22862191]\n",
      " [-1.47568588 -0.71839065 -0.45812821  1.05867647]\n",
      " [ 0.31534461 -1.83824956  0.36334103 -0.4611502 ]\n",
      " [-0.62593277  0.67487781  0.95065728  0.98416051]\n",
      " [-0.82954275 -0.34907267  0.31914979  0.92312594]\n",
      " [-0.4816247  -0.20411319 -1.0939446  -1.21788733]]\n",
      "b2:\n",
      " [[ 0.03132435  0.07535514 -0.0473796   0.07051189]]\n",
      "W3:\n",
      " [[ 0.8225384   1.34622745]\n",
      " [-0.23444396  1.16596674]\n",
      " [ 0.23419376 -0.51767749]\n",
      " [ 0.37230181  1.52713037]]\n",
      "b3:\n",
      " [[-0.04015794  0.04015794]]\n",
      "K:\n",
      " [ -0.06658705   1.54995971 -40.12142558]\n",
      "\n",
      "Final Weights:\n",
      "W1:\n",
      " [[ 0.63540203 -0.09535129  0.63272378  1.51729196 -0.12047677 -0.27462461\n",
      "   1.56774133  0.81283306]\n",
      " [-0.42394748  0.51913835 -0.48490168 -0.45185685  0.2746626  -1.86511179\n",
      "  -1.68715956 -0.57459632]\n",
      " [-0.84516675  0.38189643 -0.92112156 -1.41932565  1.60345755 -0.29908145\n",
      "   0.04022099 -1.35529317]\n",
      " [-0.44129968  0.14218005 -1.15952348  0.36902457 -0.5185287  -0.32538224\n",
      "  -0.61433177  1.88676441]]\n",
      "b1:\n",
      " [[-0.29687453 -0.10538176  0.05024016 -0.0035781  -0.2640211   0.07953984\n",
      "   0.0029589  -0.09849247]]\n",
      "W2:\n",
      " [[ 0.00706252 -1.01017751  0.79005364 -1.16758938]\n",
      " [ 0.18902981 -1.9930427  -1.29822106  0.16634437]\n",
      " [ 0.7673436   0.23995278 -0.16145651 -0.22862191]\n",
      " [-1.47568588 -0.71839065 -0.45812821  1.05867647]\n",
      " [ 0.31534461 -1.83824956  0.36334103 -0.4611502 ]\n",
      " [-0.62593277  0.67487781  0.95065728  0.98416051]\n",
      " [-0.82954275 -0.34907267  0.31914979  0.92312594]\n",
      " [-0.4816247  -0.20411319 -1.0939446  -1.21788733]]\n",
      "b2:\n",
      " [[ 0.03132435  0.07535514 -0.0473796   0.07051189]]\n",
      "W3:\n",
      " [[ 0.8225384   1.34622745]\n",
      " [-0.23444396  1.16596674]\n",
      " [ 0.23419376 -0.51767749]\n",
      " [ 0.37230181  1.52713037]]\n",
      "b3:\n",
      " [[-0.04015794  0.04015794]]\n",
      "K:\n",
      " [ -0.06658705   1.54995971 -40.12142558]\n"
     ]
    }
   ],
   "source": [
    "# Print initial and final weights\n",
    "print(\"Initial Weights:\")\n",
    "print(\"W1:\\n\", W1)\n",
    "print(\"b1:\\n\", b1)\n",
    "print(\"W2:\\n\", W2)\n",
    "print(\"b2:\\n\", b2)\n",
    "print(\"W3:\\n\", W3)\n",
    "print(\"b3:\\n\", b3)\n",
    "print(\"K:\\n\", K)\n",
    "print(\"\\nFinal Weights:\")\n",
    "print(\"W1:\\n\", W1)\n",
    "print(\"b1:\\n\", b1)\n",
    "print(\"W2:\\n\", W2)\n",
    "print(\"b2:\\n\", b2)\n",
    "print(\"W3:\\n\", W3)\n",
    "print(\"b3:\\n\", b3)\n",
    "print(\"K:\\n\", K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
